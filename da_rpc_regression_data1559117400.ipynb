{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn\n",
    "\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "init_notebook_mode(connected=True)\n",
    "import random\n",
    "import math\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some Global Constants\n",
    "categorical = 'categorical'\n",
    "numerical = 'numerical'\n",
    "categorical_null_val = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_datatype_util(col_datatype):\n",
    "    return dict( [(col,str) if val==categorical else (col,float) for col,val in col_datatype.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_datatype():\n",
    "    col_datatype = {\"keyword_term\":categorical,\"device_id\":categorical,\"browser_id\":categorical,\"user_agent\":categorical,\"user_agent_group_id\":categorical,\"domain_name\":categorical,\"domain_category_id\":categorical,\"google_url_category_id\":categorical,\"hour_id\":categorical,\"customer_id\":categorical,\"provider_account_id\":categorical,\"state_code\":categorical,\"city\":categorical,\"http_referer\":categorical}\n",
    "\n",
    "    return col_datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_default(df):\n",
    "    return dict([(col,categorical_null_val) if val==categorical else (col,round(df[col].mean(),2)) for col,val in get_col_datatype().items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\nishant.da\\Downloads\\nishant_dayal_visible_data\\\\nishant_da_rpc_regression_data.csv\",\n",
    "                 escapechar=\"\\\\\",quotechar=\"\\\"\",dtype = get_col_datatype_util(get_col_datatype()))\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"revenue\"\n",
    "weight_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Constants\n",
    "weighted_target_col = 'weighted_target'\n",
    "misc_percent = 0.005\n",
    "misc_col_value = 'Others'\n",
    "col_datatype = get_col_datatype()\n",
    "col_default = get_col_default(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weight_col is None:\n",
    "    weight_col='weight'\n",
    "    df[weight_col] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['http_referer'].replace(to_replace=\"http://\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    return [x for x in list(df.columns) if x not in [target_col,weight_col]]\n",
    "    \n",
    "def get_categorical_cols():\n",
    "    return [x for x,v in col_datatype.items() if v==categorical]\n",
    "    \n",
    "def get_numerical_cols():\n",
    "    return [x for x,v in col_datatype.items() if v==numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_colors(num_of_colors):\n",
    "    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "                 for i in range(num_of_colors)]\n",
    "    return color\n",
    "    \n",
    "def make_copy_df(df):\n",
    "    return df.copy()\n",
    "    \n",
    "def get_total(df,col):\n",
    "    return df[col].sum()\n",
    "    \n",
    "def fill_default_values(df):\n",
    "    for c in get_features(df):\n",
    "        df[c].fillna(col_default.get(c),inplace=True)\n",
    "    return df\n",
    "    \n",
    "def return_top_k(df,col,top_k):\n",
    "    temp_df = df.sort_values(by=col,ascending=False)\n",
    "    return temp_df[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique Values DataFrame\n",
    "def unique_count(df):\n",
    "    feature_col = 'Features'\n",
    "    count_col = 'Unique Count'\n",
    "    unique_count_df = pd.DataFrame(columns=[feature_col,count_col])\n",
    "    \n",
    "    unique_count_df[feature_col] = get_categorical_cols()\n",
    "    unique_count_df[count_col] = unique_count_df[feature_col].apply(lambda col: df[col].nunique())\n",
    "    \n",
    "    return unique_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Count DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count_df = unique_count(df)\n",
    "unique_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the dataframe subset and fill NULL values with some other value\n",
    "def make_group(df,col,weight_col,fill_na=False,reset_index=True):\n",
    "    temp_df = pd.DataFrame(df[col+[weight_col]])\n",
    "    \n",
    "    if fill_na:\n",
    "        temp_df = fill_default_values(temp_df)\n",
    "    \n",
    "    group = temp_df.groupby(col).agg({weight_col:'sum'})\n",
    "    \n",
    "    if reset_index:\n",
    "        group = group.reset_index()\n",
    "    \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_miscing(df,col,weight_col,misc_percent):\n",
    "    group = make_group(df,[col],weight_col)\n",
    "\n",
    "    if_misc_col = 'if_misc'\n",
    "    group[if_misc_col]=False\n",
    "    \n",
    "    summation = get_total(df,weight_col)*misc_percent*0.01\n",
    "    \n",
    "    group[if_misc_col] = group[weight_col].apply(lambda x:True if x<summation else False)\n",
    "    group[col] = group.apply(lambda x:misc_col_value if x[if_misc_col] else x[col],axis=1)\n",
    "    \n",
    "    misced_group = make_group(group,[col],weight_col)\n",
    "    return misced_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_feature_irrelevant(df,col,weight_col,misc_percent):    \n",
    "    fin_group = do_miscing(df,col,weight_col,misc_percent)\n",
    "    fin_group = fin_group[(fin_group[col]!=col_default.get(col)) & (fin_group[col]!=misc_col_value)]\n",
    "    \n",
    "    return fin_group.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_irrelevant_features(df,weight_col,misc_precent):\n",
    "    irrelevant_cols=[]\n",
    "    \n",
    "    for col in get_features(df):\n",
    "        if df[col].nunique()==df.shape[0]:\n",
    "            irrelevant_cols.append(col)\n",
    "        elif is_feature_irrelevant(df,col,weight_col,0.05):\n",
    "            irrelevant_cols.append(col)\n",
    "            \n",
    "    return irrelevant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_features(df,weight_col,misc_percent):\n",
    "    irrelevant_features = get_irrelevant_features(df,weight_col,misc_percent)\n",
    "    df.drop(irrelevant_features,axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Irrelevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_irrelevant_features(df,weight_col,misc_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_misced_df(df,target_col,weight_col):\n",
    "    df = make_copy_df(df)\n",
    "    df = fill_default_values(df)\n",
    "    \n",
    "    misced_df = pd.DataFrame(columns = list(df.columns))\n",
    "    misced_df[target_col] = df[target_col]\n",
    "    misced_df[weight_col] = df[weight_col]\n",
    "    \n",
    "    for col in get_categorical_cols():\n",
    "        misced_group = do_miscing(df,col,weight_col,misc_percent)\n",
    "        unique_values = set(misced_group[col].unique())\n",
    "        misced_df[col] = df[col].apply(lambda x: x if (x in unique_values) else misc_col_value)\n",
    "    \n",
    "    for col in get_numerical_cols():\n",
    "        misced_df[col] = df[col]\n",
    "        \n",
    "    return misced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misced DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misced_df = make_misced_df(make_copy_df(df),target_col,weight_col)\n",
    "misced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bar_trace(x,y,name=''):\n",
    "    return go.Bar(x = x,y = y,name = name,opacity=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(x,y,title):\n",
    "    trace = get_bar_trace(x,y)\n",
    "    data = [trace]\n",
    "    layout = go.Layout(title=title,xaxis=dict(type='category'))\n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_missing_count(df,col,weight_col):\n",
    "    temp_df = df[df[col].isnull()][weight_col]\n",
    "    return temp_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Values Plot (Count and Ratio)\n",
    "def missing_values_plot(df,weight_col):\n",
    "    feature_col = 'Features'\n",
    "    count_col = 'Count'\n",
    "    ratio_col = 'Ratio'\n",
    "    \n",
    "    missing = pd.DataFrame(columns=[feature_col,count_col,ratio_col])\n",
    "    \n",
    "    missing[feature_col]=get_features(df)\n",
    "    missing[count_col] = missing[feature_col].apply(lambda col: calculate_missing_count(df,col,weight_col))\n",
    "    \n",
    "    total_weight = get_total(df,weight_col)\n",
    "    \n",
    "    missing[ratio_col] = missing[count_col].apply(lambda x:x/total_weight) \n",
    "    missing.sort_values(by=count_col,ascending=False,inplace=True)\n",
    "    \n",
    "    plot_bar_chart(missing[feature_col],missing[count_col],'Missing Count')\n",
    "    plot_bar_chart(missing[feature_col],missing[ratio_col],'Missing Ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Count and Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_plot(make_copy_df(df),weight_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plt_params(width,height,title,xlabel,ylabel):\n",
    "    plt.rcParams[\"figure.figsize\"] = [width,height]\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie_chart(labels,values,title):\n",
    "    data = [go.Pie(\n",
    "        labels=labels,\n",
    "        values=values,\n",
    "        marker=dict( colors = random_colors(len(labels)) ),\n",
    "        textfont=dict( size = 20 )\n",
    "    )]    \n",
    "    layout = go.Layout(title = title)\n",
    "    \n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_chart(df,col,weight_col,top_k):\n",
    "    title = col\n",
    "    \n",
    "    group = make_group(df,[col],weight_col)\n",
    "    group_top_k = return_top_k(group,weight_col,top_k)\n",
    "    \n",
    "    set_values = set(group_top_k[col])\n",
    "    group[col] = group[col].apply(lambda x:misc_col_value if x not in set_values else x)\n",
    "    \n",
    "    group = make_group(group,[col],weight_col)\n",
    "    \n",
    "    plot_pie_chart(group[col],group[weight_col],title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(df,val,col,weight_col):\n",
    "    index = df[weight_col].searchsorted(val)\n",
    "    ret_df = df.iloc[index].reset_index()\n",
    "    \n",
    "    return (ret_df.iloc[0][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_first_and_third_quartile(arr,df,total_len,factor,col,weight_col):\n",
    "    if ((total_len+1)%4)==0:\n",
    "        arr.append(get_value(df,(total_len+1)*factor,col,weight_col))\n",
    "    else:\n",
    "        arr.append((get_value(df,math.ceil((total_len+1)*factor),col,weight_col)+get_value(df,math.floor((total_len+1)*factor),col,weight_col))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartiles(df,col,weight_col):\n",
    "    df = make_copy_df(df)\n",
    "    df.sort_values(by=col,inplace=True)\n",
    "    df.reset_index()\n",
    "    df[weight_col] = df[weight_col].cumsum()\n",
    "    \n",
    "    total_len = df.iloc[df.shape[0]-1][weight_col]\n",
    "    arr = list()\n",
    "    \n",
    "    arr.append(df.iloc[0][col])\n",
    "    append_first_and_third_quartile(arr,df,total_len,1/4,col,weight_col)\n",
    "    \n",
    "    if total_len%2==1:\n",
    "        arr.append((get_value(df,total_len/2,col,weight_col)+get_value(df,(total_len/2)+1,col,weight_col))/2)\n",
    "    else:\n",
    "        arr.append(get_value(df,(total_len+1)/2,col,weight_col))\n",
    "    \n",
    "    append_first_and_third_quartile(arr,df,total_len,3/4,col,weight_col)\n",
    "    arr.append(df.iloc[df.shape[0]-1][col])\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df,col,weight_col):\n",
    "    quar = quartiles(df,col,weight_col)\n",
    "    iqr_range = quar[3]-quar[1]\n",
    "    \n",
    "    df = df[df[col]>(quar[1]-1.5*iqr_range)]\n",
    "    df = df[df[col]<(quar[3]+1.5*iqr_range)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(df,col,weight_col,nbins):\n",
    "    title = col\n",
    "    \n",
    "    temp_df = df[[col,weight_col]]\n",
    "    temp_df = fill_default_values(temp_df)\n",
    "    temp_df = remove_outliers(temp_df,col,weight_col)\n",
    "\n",
    "    set_plt_params(20,15,title,col,'Weight')\n",
    "    plt.hist(temp_df[col],bins=nbins,weights=temp_df[weight_col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_plot(df,col,weight_col):\n",
    "    for c in col:\n",
    "        if col_datatype.get(c)==categorical:\n",
    "            pie_chart(df,c,weight_col,100)\n",
    "        elif col_datatype.get(c)==numerical:\n",
    "            hist_plot(df,c,weight_col,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diff from Classification\n",
    "def get_avg_values(df,df_weight,col,weight_col,weighted_target_col):\n",
    "    columns = set([x for x in df.index])\n",
    "\n",
    "    df = df.to_dict()\n",
    "    df_weight = df_weight.to_dict()\n",
    "\n",
    "    values = dict()\n",
    "    for i in columns:\n",
    "        num = df.get(weighted_target_col).get(i) if df.get(weighted_target_col).get(i) is not None else 0\n",
    "        den = df_weight.get(weight_col).get(i) if df_weight.get(weight_col).get(i) is not None else 0\n",
    "        values[i] = 0 if num==0 else num/den\n",
    "\n",
    "    values.pop(col_default.get(col),None)\n",
    "    values.pop(misc_col_value,None)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_feature_val(df,col,target_col,weight_col,weighted_target_col,top_k):\n",
    "    temp_df = df[[col,target_col,weight_col]]\n",
    "    temp_df[weighted_target_col] = temp_df[target_col]*temp_df[weight_col]\n",
    "        \n",
    "    group_weight = return_top_k(make_group(temp_df,[col],weight_col),weight_col,top_k)\n",
    "    group = make_group(temp_df,[col],weighted_target_col)\n",
    "    \n",
    "    group= group[group[col].isin(group_weight[col])]\n",
    "    \n",
    "    group.set_index(col,inplace=True)\n",
    "    group_weight.set_index(col,inplace=True)\n",
    "    \n",
    "    return get_avg_values(group,group_weight,col,weight_col,weighted_target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_val_bar_plot(df,col,target_col,weight_col,weighted_target_col,top_k):\n",
    "    values = get_topk_feature_val(df,col,target_col,weight_col,weighted_target_col,top_k)\n",
    "    \n",
    "    sorted_values = sorted(values.items(), key=lambda kv: kv[1],reverse=True)\n",
    "    sorted_x = [x[0] for x in sorted_values]\n",
    "    sorted_y = [x[1] for x in sorted_values]\n",
    "    \n",
    "    plot_bar_chart(sorted_x,sorted_y,'Average Target Value : '+str(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_plot(df,col,weight_col,nbins):\n",
    "    title = col\n",
    "    \n",
    "    temp_df = df[[col,weight_col]]\n",
    "    temp_df = fill_default_values(temp_df)\n",
    "    temp_df = remove_outliers(temp_df,col,weight_col)\n",
    "    \n",
    "    ax = sns.distplot(temp_df[col],kde=True,bins=nbins,\n",
    "                 hist_kws={'weights': temp_df[weight_col]})\n",
    "    ax.set(xlabel=col, ylabel='Probability',title=title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_value_plot(df,col,target_col,weight_col,weighted_target_col):\n",
    "    for c in col:\n",
    "        if col_datatype.get(c)==categorical:\n",
    "            avg_val_bar_plot(df,c,target_col,weight_col,weighted_target_col,100)\n",
    "        elif col_datatype.get(c)==numerical:\n",
    "            dist_plot(df,c,weight_col,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sns_params(figsize,ax_facecolor,fig_facecolor):\n",
    "    sns.set(rc={'figure.figsize':figsize,'axes.facecolor':ax_facecolor, 'figure.facecolor':fig_facecolor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_util(df,x_col,y_col,weight_col):\n",
    "    set_sns_params((12,9),'white','white')\n",
    "    sns.stripplot(x=x_col,y=y_col,data=df,jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(df,columns,y_col,weight_col,col_datatype):\n",
    "    if col_datatype.get(y_col)==numerical:\n",
    "        for col in columns:\n",
    "            scatter_plot_util(df,col,y_col,weight_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot_util(df,title,col,weight_col,group_col=None):\n",
    "    df = make_copy_df(df)\n",
    "    data = []\n",
    "    \n",
    "    if group_col==None:\n",
    "        arr = quartiles(df,col,weight_col)\n",
    "        arr.insert(int(len(arr)/2),arr[int(len(arr)/2)])\n",
    "        data.append(go.Box(y=arr))\n",
    "    else:\n",
    "        for c in df[group_col].unique():\n",
    "            arr = quartiles(df[df[group_col]==c],col,weight_col)\n",
    "            arr.insert(int(len(arr)/2),arr[int(len(arr)/2)])\n",
    "            data.append(go.Box(y=arr,name=c))\n",
    "    \n",
    "    layout = go.Layout(title = title)\n",
    "    fig = go.Figure(data=data,layout=layout)\n",
    "    \n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(df,columns,weight_col,col_datatype,group_col=None):\n",
    "    for col in columns:\n",
    "        if col_datatype.get(col)==numerical:\n",
    "            box_plot_util(df,'Box Plot',col,weight_col,group_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Encoded Data\n",
    "def categorical_to_numerical_TBS(col,default_val,group,group_weight,weight_col,weighted_target_col,prior,include_na=False):\n",
    "    if (include_na==True) & (col==default_val):\n",
    "        return None\n",
    "    \n",
    "    num = group.get(weighted_target_col).get(col) if group.get(weighted_target_col).get(col) is not None else 0\n",
    "    den = group_weight.get(weight_col).get(col) if group_weight.get(weight_col).get(col) is not None else 0\n",
    "    den = den+1\n",
    "    retval = (num+prior)/den if num!=0 else 0\n",
    "    return retval\n",
    "\n",
    "v_categorical_to_numerical_TBS = np.vectorize(categorical_to_numerical_TBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior(df,target_col,weight_col):\n",
    "    prior = ((df[target_col]*df[weight_col]).sum())/df[weight_col].sum()\n",
    "    return round(prior,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_numerical_df(df,target_col,weight_col,weighted_target_col,include_na=True):\n",
    "    df = make_copy_df(df)\n",
    "    df = fill_default_values(df)\n",
    "    \n",
    "    numerical_df = pd.DataFrame(columns = list(df.columns))\n",
    "    numerical_df[target_col] = df[target_col]\n",
    "    numerical_df[weight_col] = df[weight_col]\n",
    "    \n",
    "    df[weighted_target_col] = df[target_col]*df[weight_col]\n",
    "    prior = calculate_prior(df,target_col,weight_col)\n",
    "    \n",
    "    for col in get_categorical_cols():\n",
    "        group = make_group(df,[col],weighted_target_col,fill_na=False,reset_index=False).to_dict()\n",
    "        group_weight = make_group(df,[col],weight_col,fill_na=False,reset_index=False).to_dict()\n",
    "        default_val = col_default.get(col)\n",
    "        numerical_df[col] = v_categorical_to_numerical_TBS(df[col],default_val,group,group_weight,weight_col,\n",
    "                                                           weighted_target_col,prior,include_na)\n",
    "                                                            \n",
    "    for col in get_numerical_cols():\n",
    "        numerical_df[col] = df[col]\n",
    "        \n",
    "    return numerical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df_without_na = make_numerical_df(misced_df,target_col,weight_col,weighted_target_col,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(df,col, weight_col):\n",
    "    return (df[col]*df[weight_col]).sum()/df[weight_col].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_std(df,columns,weight_col):\n",
    "    den = get_total(df,weight_col)\n",
    "    std_list = list()\n",
    "    \n",
    "    for col in columns:\n",
    "        mean = weighted_mean(df,col,weight_col)\n",
    "        diff = (df[col]-mean)**2\n",
    "        diff = diff*df[weight_col]\n",
    "        std_list.append(math.sqrt(diff.sum()/den))\n",
    "        \n",
    "    return std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coeff_df(df,model,columns):\n",
    "    coeff_df = pd.DataFrame(columns=['col','coeff','std','Coefficient'])\n",
    "    coeff_df['coeff'] = list(model.coef_)\n",
    "    coeff_df['col'] = columns\n",
    "    coeff_df['std'] = weighted_std(df,columns,weight_col)\n",
    "    coeff_df['Coefficient'] = abs(coeff_df['coeff']*coeff_df['std'])\n",
    "    coeff_df = coeff_df.sort_values(by='Coefficient',ascending=False)\n",
    "    coeff_df.drop(['coeff','std'],axis=1,inplace=True)\n",
    "    return coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_regression_model(df,target_col,weight_col,columns=None,reg=False,alpha=1):\n",
    "    train_df = make_copy_df(df)\n",
    "    \n",
    "    target = train_df[target_col]\n",
    "    train_df.drop([target_col],axis=1,inplace=True)\n",
    "    weight = train_df[weight_col]\n",
    "    train_df.drop([weight_col],axis=1,inplace=True)\n",
    "    \n",
    "    if columns is not None:\n",
    "        train_df.drop(columns,axis=1,inplace=True)\n",
    "    \n",
    "    if reg:\n",
    "        model = Lasso(alpha=alpha)\n",
    "    else:\n",
    "        model = LinearRegression(verbose=1)\n",
    "        \n",
    "    model.fit(train_df,target)\n",
    "    \n",
    "    train_df[target_col] = df[target_col]\n",
    "    train_df[weight_col] = df[weight_col]\n",
    "    coeff_df = get_coeff_df(train_df,model,get_features(train_df))\n",
    "    \n",
    "    return (model,coeff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model,coeff_df = fit_linear_regression_model(numerical_df_without_na,target_col,weight_col,None,True,0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor,plot_importance,plot_tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Feature Importance\n",
    "def plot_feature_importance(model,importance_type):\n",
    "    plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "    plot_importance(model,importance_type=importance_type)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Tree Models\n",
    "def plot_and_save_boosted_trees(model,num_of_trees,filename,width,height):\n",
    "    plt.rcParams[\"figure.figsize\"] = [width,height]\n",
    "\n",
    "    i=0\n",
    "    for i in range(num_of_trees):\n",
    "        plot_tree(model,num_trees=i)\n",
    "        plt.savefig(filename+str(i)+\".png\",dpi=150)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_features(model):\n",
    "    features_importance = model.get_booster().get_score(importance_type='cover')\n",
    "    sorted_features_importance = sorted(features_importance.items(), key=lambda kv: kv[1],reverse=True)\n",
    "    \n",
    "    ret_list = list()\n",
    "    for i in range(len(sorted_features_importance)):\n",
    "        ret_list.append(sorted_features_importance[i][0])\n",
    "    \n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgboost_model(df,target_col,weight_col):\n",
    "    df = make_copy_df(df)\n",
    "\n",
    "    target = df[target_col]\n",
    "    df.drop([target_col],axis=1,inplace=True)\n",
    "    weight = df[weight_col]\n",
    "    df.drop([weight_col],axis=1,inplace=True)\n",
    "    \n",
    "    model = XGBRegressor(max_depth=5,learning_rate=0.1,n_estimators=10,missing=None,silent=False)\n",
    "    model.fit(df,target,sample_weight=weight)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = make_numerical_df(misced_df,target_col,weight_col,weighted_target_col,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = fit_xgboost_model(numerical_df,target_col,weight_col)\n",
    "imp_feature_list_xgboost = get_important_features(xgboost_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance(XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(xgboost_model,'cover')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_data(df):\n",
    "    df = make_copy_df(df)\n",
    "    \n",
    "    list_le = dict()\n",
    "    for col in get_features(df):\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        list_le[col] = le\n",
    "        \n",
    "    return df,list_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded_df,list_le = label_encode_data(misced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_lightgbm(model):\n",
    "    plt.rcParams[\"figure.figsize\"] = [12,9]\n",
    "    lgb.plot_importance(model,importance_type='gain')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_features_lightgbm(df,model):\n",
    "    ret_list = list(zip(list(df.columns),lightgbm_model.booster_.feature_importance(importance_type='gain')))\n",
    "    \n",
    "    return [x[0] for x in sorted(ret_list, key=lambda x: x[1],reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lightgbm_model(df,target_col,weight_col):\n",
    "    df = make_copy_df(df)\n",
    "    \n",
    "    target = df[target_col]\n",
    "    df.drop([target_col],axis=1,inplace=True)\n",
    "    weight = df[weight_col]\n",
    "    df.drop([weight_col],axis=1,inplace=True)\n",
    "    \n",
    "    model = lgb.LGBMRegressor(num_leaves=20,\n",
    "                               max_depth=4,learning_rate=0.01,objective='regression',n_estimators=100)\n",
    "    \n",
    "    model.fit(df,target,sample_weight=weight,categorical_feature=get_categorical_cols())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_model = fit_lightgbm_model(label_encoded_df,target_col,weight_col)\n",
    "imp_feature_list_lightgbm = get_important_features_lightgbm(misced_df,lightgbm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_lightgbm(lightgbm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mean_util(df,col_list,rank_dict):\n",
    "    col_set = set()\n",
    "    \n",
    "    i=1\n",
    "    for col in col_list:\n",
    "        rank_dict[col] = rank_dict[col]+i\n",
    "        col_set.add(col)\n",
    "        i +=1\n",
    "        \n",
    "    for col in get_features(df):\n",
    "        if col not in col_set:\n",
    "            rank_dict[col] +=i\n",
    "    \n",
    "    return rank_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_mean(df,coeff_df_woe,coeff_col,imp_feature_list_xgboost,imp_feature_list_lightgbm):\n",
    "    rank_dict = {}\n",
    "    for col in get_features(df):\n",
    "        rank_dict[col]=0\n",
    "        \n",
    "    rank_dict = rank_mean_util(df,list(coeff_df_woe[coeff_col]),rank_dict)\n",
    "    rank_dict = rank_mean_util(df,imp_feature_list_xgboost,rank_dict)\n",
    "    rank_dict = rank_mean_util(df,imp_feature_list_lightgbm,rank_dict)\n",
    "    \n",
    "    for col in rank_dict.keys():\n",
    "        rank_dict[col] = rank_dict[col]/3\n",
    "    \n",
    "    sorted_by_rank = sorted(rank_dict.items(), key=lambda kv: kv[1])\n",
    "    return [x[0] for x in sorted_by_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_list = rank_mean(misced_df,coeff_df,'col',imp_feature_list_xgboost,imp_feature_list_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_list(ret_list,columns=None):\n",
    "    if columns is not None:\n",
    "        return list(set(ret_list+columns))\n",
    "    else:\n",
    "        return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_list = ret_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_plot(misced_df,ret_list,weight_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Values Plot(Average Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_value_plot(misced_df,ret_list,target_col,weight_col,weighted_target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_plot(misced_df,[target_col],weight_col,col_datatype)\n",
    "ax = plt.boxplot(misced_df[target_col],notch=True,showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot(misced_df,['device_id'],target_col,weight_col,col_datatype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Feature Importance(Next Candidate Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def conditional_feature_importance_util(df,target,weight,columns,model,islasso):\n",
    "    train_df = df[columns]\n",
    "    r2_df = pd.DataFrame(columns=['Features','R2 Coeff'])\n",
    "    \n",
    "    if islasso:\n",
    "        model.fit(train_df,target)\n",
    "        initial_r2_coeff = model.score(train_df,target)\n",
    "    else:\n",
    "        model.fit(train_df,target,sample_weight=weight)\n",
    "        predicted_target = model.predict(train_df)\n",
    "        initial_r2_coeff = r2_score(target,predicted_target,sample_weight=weight)\n",
    "        \n",
    "    for col in set(get_features(df))-set(columns):\n",
    "        train_df[col] = df[col]\n",
    "        \n",
    "        if islasso:\n",
    "            model.fit(train_df,target)\n",
    "            r2_coeff = model.score(train_df,target)\n",
    "        else:\n",
    "            model.fit(train_df,target,sample_weight=weight)\n",
    "            predicted_target = model.predict(train_df)\n",
    "            r2_coeff = r2_score(target,predicted_target,sample_weight=weight)\n",
    "        \n",
    "        r2_df = r2_df.append({'Features':col,'R2 Coeff':r2_coeff-initial_r2_coeff},ignore_index=True)\n",
    "        train_df.drop(col,axis=1,inplace=True)\n",
    "        \n",
    "    return r2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_feature_importance(df,df_with_null,columns):\n",
    "    df = make_copy_df(df)\n",
    "    \n",
    "    target = df[target_col]\n",
    "    df.drop([target_col],axis=1,inplace=True)\n",
    "    weight = df[weight_col]\n",
    "    df.drop([weight_col],axis=1,inplace=True)\n",
    "    \n",
    "    model = Lasso(alpha=0.003)\n",
    "    r2_linear = conditional_feature_importance_util(df,target,weight,columns,model,True)\n",
    "    \n",
    "    model = XGBRegressor(max_depth=5,learning_rate=0.1,n_estimators=5,booster='gbtree',missing=None,silent=False)\n",
    "    r2_xgboost = conditional_feature_importance_util(df_with_null,target,weight,columns,model,False)\n",
    "    \n",
    "    return (r2_linear,r2_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r2_linear,r2_xgboost) = conditional_feature_importance(numerical_df_without_na,numerical_df,['keyword_term'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Increase on addition of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_linear = r2_linear.sort_values(by = \"R2 Coeff\",ascending=False)\n",
    "r2_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_xgboost = r2_xgboost.sort_values(by = \"R2 Coeff\",ascending=False)\n",
    "r2_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_bias_corrected(df,col1,col2,weight_col):\n",
    "    confusion_matrix = pd.crosstab(df[col1], df[col2], df[weight_col], aggfunc=sum)\n",
    "    confusion_matrix.fillna(0,inplace=True)\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_corr_df(df,weight_col,target_col=None):\n",
    "    columns = get_categorical_cols()\n",
    "    if(len(columns)==1):\n",
    "        return\n",
    "    \n",
    "    if target_col is not None:\n",
    "        corr = pd.DataFrame(index=columns,columns=[target_col])\n",
    "        i=0\n",
    "        while i<len(columns):\n",
    "            corr.ix[columns[i]][target_col] = cramers_bias_corrected(df,columns[i],target_col,weight_col)\n",
    "            i+=1\n",
    "        corr.sort_values(by=target_col,ascending=False,inplace=True)\n",
    "    else:\n",
    "        corr = pd.DataFrame(index=columns,columns=columns)\n",
    "        \n",
    "        i=0\n",
    "        while i<len(columns):\n",
    "            j=i\n",
    "            while j<len(columns):\n",
    "                if i==j:\n",
    "                    corr.ix[columns[i]][columns[j]] = 1\n",
    "                else:\n",
    "                    corr.ix[columns[j]][columns[i]] = cramers_bias_corrected(df,columns[i],columns[j],weight_col)\n",
    "                    corr.ix[columns[i]][columns[j]] = corr.ix[columns[j]][columns[i]]\n",
    "                j+=1\n",
    "            i+=1\n",
    "            \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_corr = categorical_corr_df(misced_df,weight_col)\n",
    "cat_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(df, col1, col2, weight_col):\n",
    "    mean_col1 = weighted_mean(df,col1,weight_col)\n",
    "    mean_col2 = weighted_mean(df,col2,weight_col)\n",
    "    return ((df[weight_col]*((df[col1]-mean_col1)*(df[col2]-mean_col2))).sum())/get_total(df,weight_col)\n",
    "\n",
    "def get_pearson_coeff(df,col1,col2,weight_col):\n",
    "    num = cov(df,col1,col2,weight_col)\n",
    "    std1 = weighted_std(df,[col1],weight_col)[0]\n",
    "    std2 = weighted_std(df,[col2],weight_col)[0]\n",
    "    den = std1*std2\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_corr_df(df,weight_col,target_col=None):\n",
    "    #Change the below line to get_numerical_columns\n",
    "    columns = get_numerical_cols()\n",
    "    if(len(columns)==1):\n",
    "        return\n",
    "    \n",
    "    if target_col is not None:\n",
    "        corr = pd.DataFrame(index=columns,columns=[target_col])\n",
    "        i=0\n",
    "        while i<len(columns):\n",
    "            corr.ix[columns[i]][target_col] = get_pearson_coeff(df,columns[i],target_col,weight_col)\n",
    "            i+=1\n",
    "        corr.sort_values(by=target_col,ascending=False,inplace=True)\n",
    "    else:\n",
    "        corr = pd.DataFrame(index=columns,columns=columns)\n",
    "    \n",
    "        i=0\n",
    "        while i<len(columns):\n",
    "            j=i\n",
    "            while j<len(columns):\n",
    "                corr.ix[columns[j]][columns[i]] = get_pearson_coeff(df,columns[i],columns[j],weight_col)\n",
    "                corr.ix[columns[i]][columns[j]] = corr.ix[columns[j]][columns[i]]\n",
    "                j+=1\n",
    "            i+=1\n",
    "            \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_corr = numerical_corr_df(misced_df,weight_col)\n",
    "num_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with Target\n",
    "corr_target = numerical_corr_df(misced_df,weight_col,target_col)\n",
    "corr_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Feature Values having similar target behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cluster(cluster_fig):\n",
    "    cluster_fig.render(view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_clustering(df,col,target_col,weight_col):\n",
    "    target = df[target_col]\n",
    "    weight = df[weight_col]\n",
    "    \n",
    "    train_df = pd.DataFrame(df[col])\n",
    "    \n",
    "    model = lgb.LGBMRegressor(boosting_type='gbdt',num_leaves=14,\n",
    "                               max_depth=4,learning_rate=1,objective='regression',n_estimators=1, max_cat_threshold = 1000)\n",
    "    \n",
    "    model.fit(train_df,target,sample_weight=weight,categorical_feature=col)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_cluster = lightgbm_clustering(label_encoded_df,[\"hour_id\"],target_col,weight_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_fig = lgb.create_tree_digraph(lightgbm_cluster,tree_index=0,filename='hour_tree',format='png')\n",
    "save_cluster(cluster_fig)\n",
    "cluster_fig"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
